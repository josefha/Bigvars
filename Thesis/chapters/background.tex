This sections will cover all necessary information about Encore and other subjects related to this thesis. 
\section{Encore}
Encore is developed at the Programming Languages Group \citep{researchgroup} at Uppsala University  and is founded by the European project Upscale \citep{upscale}.  Encore is planed to be released as open sourced summer 2016 \citep{encore}.\\

Encore is a high-level object oriented with many functional features, it focus on parallelism and achieves it with the actor model. Every Encore program has at least one actor but Encore has support for  millions of actors, even if the machine only has a few cores. \\

Encores compiler is written in Haskell and it translates encore code to C code which later can be compiled with a C compiler. The encore philosophy, ‘By adopting the actor concurrency model, Encore avoids scalability problems associated with multi-threading. Encore offers an array of concurrency and parallelism abstractions beyond the pure actor model. These abstractions use Encore's capability type system to ensure that no data races occur.’ \citep{encore}

\section{Active-Objects}
If you declarer an active class in Encore all method calls is asynchronous and methods are called with the bang operator instead of the dot as for normal classes. Each active-object has it’s own message queue and process each message sequentially. Each active-object lives in one actor and sense the actors don’t share memory and restrictions on how objects are shared there can be no data-races. The big benefit of the active-objects model is that each active objects can be scheduled in parallel and parallelism happen by default. The negative side is that there are an overhead when using message sending instead of normal method calls. 
Example here. 
\section{Futures}
Futures is one important concept if you want to understand i how encore works. In Encore and the active-object model there are a lot  of message sending between active-objects. Messages may return futures. A future is a placeholder for a value that being returned from an asynchronous call and is returned immediately to the callee. Reading a value before the futures has been fulfilled will result in blocking state where the reader waits until the value have been calculated and stored in that future.

\section{Kappa - Type System}

\section{Data Parallel Model}
In the Data Parallel Model focus on preforming operations on a data sets that often are structured as an array or cube. Tasks are preformed on the data but each task work on a different part of the data-structure. Data parallelism can easily be applied when calculations don’t need result from other parts of the dataset. If then the dataset is big the program will run faster. 


\section{MapReduce Framework}
MapReduce is a programming model that have been implemented in many different programming languages. It’s for problems that can be parallelised and have a large amount of data input and has access to big numbers of computational nodes. The programmer then only needs to prepare the input and write to functions, one Map function and one Reduce function, the algorithm will provide the rest. The three main steps of the algorithm is “Map”, “Shuffle” and “Reduce”. In the Map stage every node applies the users map function to the local data. The shuffle step then redistribute the data depending on the output from the map step. The Reduce step then finally process each group of data and outputs a result \citep{mapreduce}.
